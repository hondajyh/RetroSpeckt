{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Machine Learning Hawaii Kaggle Competition\n",
    "*We are deviating from our regularly scheduled programming to apply our skills learned so far to a Kaggle Competition and get a preview of what Machine Learning is all about while building out some connections to other local data science and machine learning practitioners.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytical Process Big Picture\n",
    "![Curriculum Summary](../curriculum_summary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We're going to try our hands at modeling\n",
    "Machine Learning is all the rage, and Kaggle is emerging as one of the best resources to get some practice as well as learn the state of the art\n",
    "- Why are machine learning competitions such a valuable educational resource?\n",
    "- How does the machine learning community work?\n",
    "- How does Kaggle do such a good job of teaching the newest ideas in Machine Learning?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Key Questions\n",
    "- What is a Kaggle competition, and what are we trying to solve?\n",
    "- What is Kaggle?\n",
    "- What makes one submission better than another?\n",
    "- What are the different parts of a Kaggle Competition, and how do they relate to each other.\n",
    "\n",
    "## Key Concepts and Definitions\n",
    "\n",
    "Kaggle\n",
    "- Kernel\n",
    "- Grandmaster\n",
    "- Message Board\n",
    "- Leaderboard\n",
    "- Benchmark\n",
    "- test set\n",
    "- training set\n",
    "\n",
    "Machine Learning\n",
    "- Optimization\n",
    "- Generalization\n",
    "- Training set\n",
    "- Overfitting\n",
    "- Predictor\n",
    "- Learner / classifier\n",
    "- Model\n",
    "- Induction\n",
    "- Bias / variance\n",
    "- Cross validation\n",
    "- Curse of dimensionality\n",
    "- Feature engineering\n",
    "- Machine learning algorithm\n",
    "- Ensemble models\n",
    "- Bagging\n",
    "- Boosting\n",
    "- Stacking\n",
    "(List was largely inspired by: https://towardsdatascience.com/12-useful-things-to-know-about-machine-learning-487d3104e28\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of Kaggle Platform and of Competition\n",
    "*From 3/30 Kickoff Meeting*\n",
    "\n",
    "1.) Sign up for Kaggle Account\n",
    "Matt / Tom / Mike (TheBus)\n",
    "\n",
    "Expert / Grand Master\n",
    "\n",
    "Will post the private link to join competition.\n",
    "Will need the private link\n",
    "-github\n",
    "-slack\n",
    "-email\n",
    "-email deck\n",
    "\n",
    "### Universal Rules\n",
    "- One account per participant.\n",
    "- No private sharing outside of teams. Share within team. If you share with someone share with everyone.\n",
    "- Team Mergers (are allowed)\n",
    "- No Maximum Team Size\n",
    "- Submission Limits\n",
    "- Can select your two 2 final submissions\n",
    "- Running through April 30th.\n",
    "- Good to understand the final validation metric.\n",
    "\n",
    "### Data sets\n",
    "- sample submission. Can see what you’re supposed to predict.\n",
    "- test is for testing predictions\n",
    "- training is for training models\n",
    "\n",
    "### Kernels\n",
    "- Good way to share an idea\n",
    "- Share a model\n",
    "\n",
    "Kernels are runnable notebooks. Owned by Google. Good resources\n",
    "Good place to do a lot of computing.\n",
    "\n",
    "Beat the Benchmark Kernel - \n",
    "Anukis - uses a template.\n",
    "\n",
    "Kaggle is a good place to stay up to date with modern techniques - not stuff that you’ll learn in school.\n",
    "\n",
    "\n",
    "### Discusion Boards\n",
    "Kernels and Discussions are a place to share where you won’t get disqualified.\n",
    "Nice way to trade ideas. \n",
    "\n",
    "Encourage using discussion - can even be a grandmaster of discussions\n",
    "\n",
    "Will score based on 30% of the data. - can use the leaderboard to validate your performance. But it’s not the only way to do it.\n",
    "\n",
    "The remaining 70% will be available in private leaderboard after competition ends\n",
    "\n",
    "### Teams\n",
    "Can create team using the team feature.\n",
    "You can only invite one person at a time. So invite the people who are ready to accept.\n",
    "\n",
    "I you get disqualified, the whole team gets disqualified.\n",
    "\n",
    "only 5 submissions for the team - so protocol for submissions.\n",
    "\n",
    "### Competition Details - Task\n",
    "Predict the quantity of items sold in online retail transactions\n",
    "- given sales data\n",
    "- predict the number items sold in a transaction\n",
    "- evaluated on how well your predictions match reality\n",
    "\n",
    "What does a match mean?\n",
    "\n",
    "Data\n",
    "- real data from online transactions\n",
    "\n",
    "Questions about the data - EDA - good to share in a kernel.\n",
    "Test set - withhold the quantity.\n",
    "\n",
    "Trying to predict quantities. \n",
    "\n",
    "It’s ok to use all of your submissions. Get a score up and you can always incrementally improve.\n",
    "\n",
    "### Kernels - Running Google’s resources to run your code.\n",
    "Will be judging the kernes subjectively\n",
    "- Originality\n",
    "- Helpfulness (insights? help solve the problem) \n",
    "- Correctness\n",
    "\n",
    "\n",
    "Some prizes for Funding\n",
    "\n",
    "### Tutorials\n",
    "- will be providing R and python code.\n",
    "\n",
    "- Training and Prediction - Gradient Boosted Decision Trees (like neural networks, but don’t require as much tuning)\n",
    "\n",
    "- Cross Validation\n",
    "\n",
    "- Model Selection\n",
    "\n",
    "- Ensembling\n",
    "\n",
    "### Final Words\n",
    "Ends April 30th 2PM HST\n",
    "May 4 - top 3 winners discuss their solutions.\n",
    "Best kernel explain their kernel\n",
    "Prizes if there are prizes.\n",
    "\n",
    "Recommend Teaming up. Expand professional network. Good way to get insight into what’s going on in the industry.\n",
    "\n",
    "Can load your own datasets and call from the datasets\n",
    "\n",
    "\n",
    "KAggle is the fastest way to learn anything, R, Python, whatever.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

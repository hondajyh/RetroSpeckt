{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7fbfb891-6794-4584-9c00-ede5e8a8ba0f",
    "_uuid": "5aca4e1b81b52102ec85a107f821714014f0bdf1"
   },
   "source": [
    "# JON'S HiML Competition RFG_Log Model (v 2.6)\n",
    "## Make Date: 04/13/18\n",
    "I found out RFG has tuning parameters. Let's see if we can improve prediction errors of each combo done in v 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "#Some initialization procedures:\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "# load in data files\n",
    "# FILE_DIR = '../input/hawaiiml-data'\n",
    "# for f in os.listdir(FILE_DIR):\n",
    "#     print('{0:<30}{1:0.2f}MB'.format(f, 1e-6*os.path.getsize(f'{FILE_DIR}/{f}')))\n",
    "FILE_DIR = '../Sprint09alt_Machine_Learning_Hawaii_Kaggle_Competition'\n",
    "df_train = pd.read_csv(f'{FILE_DIR}/train.csv', encoding='ISO-8859-1') #write training data to dataframe\n",
    "df_test = pd.read_csv(f'{FILE_DIR}/test.csv', encoding='ISO-8859-1') # Read the test data\n",
    "\n",
    "#define the error function:\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((np.log1p(y_true) - np.log1p(y_pred))**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ff9f1761-c91d-4ee4-bfe8-a9b09b7ee31a",
    "_uuid": "4b5c96480b52b12cb00f951f4caf86bee8671a1a"
   },
   "source": [
    "# Prediction Target\n",
    "We want to predict the quantity data field.    \n",
    "By convention, we define this target as 'y'.  \n",
    "We know quantity is highly skewed. See if a log transform will help.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "e9777448-7e1c-4431-91ba-8278ef408e90",
    "_uuid": "7ce0ac11027bab5c459434ee85fdf943bf655e3e"
   },
   "outputs": [],
   "source": [
    "y = df_train.quantity\n",
    "logy = np.log1p(df_train.quantity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# Define ML Predictors\n",
    "build a function to go through each combination of predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7bff28a9-8df2-4545-a161-7e2ac034603e",
    "_uuid": "42ec8896695db7f7c0f89e09812deea081e4c131"
   },
   "source": [
    "### Here is the list of columns we can choose predictors from. To keep it simple, just select from numeric data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "49be0d0a-9910-40e8-a912-a20310183e08",
    "_uuid": "f92705d0747bc4744f0eedc2b900a717c5071c43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names & Data Types: \n",
      " id               int64\n",
      "date            object\n",
      "time            object\n",
      "invoice_id       int64\n",
      "stock_id         int64\n",
      "customer_id      int64\n",
      "country         object\n",
      "description     object\n",
      "unit_price     float64\n",
      "quantity         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('Column Names & Data Types: \\n', df_train.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0c79a0fb-ea3a-4de6-946e-39215db1014c",
    "_uuid": "4bbadda9ed133f8ec4ed40dbd40081e7c5635c6d"
   },
   "source": [
    "## Define feature combination picker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "f810fcc3-daab-4599-936b-d3d08d4fdc7d",
    "_uuid": "df2153cd07cacfa2c55083c47e225cff21db357d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stock_id']\n"
     ]
    }
   ],
   "source": [
    "ls_AllPredictors = ['invoice_id', 'stock_id', 'customer_id', 'unit_price']\n",
    "\n",
    "# https://stackoverflow.com/questions/464864/how-to-get-all-possible-combinations-of-a-list-s-elements\n",
    "from itertools import chain, combinations\n",
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)  # allows duplicate elements\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "#build combos:\n",
    "ls_PredictorCombos = [list(combo[1]) for combo in enumerate(powerset(ls_AllPredictors), 1)]\n",
    "print (ls_PredictorCombos[2])\n",
    "# display(df_train[ls_PredictorCombos[2]])\n",
    "def GetX(comboID,df):\n",
    "    return df[ls_PredictorCombos[comboID]]\n",
    "# display(GetX(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dac2a3c4-1cd6-46ab-8400-485d1521ef33",
    "_uuid": "2ccaea24236a5cae5b01524ae0dbe81c71af131e"
   },
   "source": [
    "# Score Different Random Forest Regressor Models\n",
    "Iteratively try different parameter tunings on each predictor combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "a5cc7dee-74be-4115-8c8d-e84ab88c565a",
    "_uuid": "f8716a2b79957c3da577a755a9e0d29ec21a2434",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Run_RFG(SeedVal, X, logy, i_n_estimators=10,i_min_samples_leaf=1, i_max_leaf_nodes=None, pct_max_features = 100, i_n_jobs=1):\n",
    "    #fit, predict, and then evaluate the passed in mod = el using passed in values (e.g. training set)\n",
    "    #return back RMSLE value and trained model\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "    myModel = RandomForestRegressor(\n",
    "        n_estimators = i_n_estimators, \n",
    "        min_samples_leaf = i_min_samples_leaf,\n",
    "        max_leaf_nodes = i_max_leaf_nodes, \n",
    "        max_features = pct_max_features / 100, \n",
    "        oob_score = True,\n",
    "        n_jobs=i_n_jobs, \n",
    "        random_state=SeedVal)\n",
    "    train_X, val_X, train_y, val_y = train_test_split(X, logy,random_state = SeedVal) #split training data into a test and train part\n",
    "    myModel.fit(train_X, train_y)\n",
    "    predicted_vals = np.expm1(myModel.predict(val_X)) #transform predicted values from log to \"normal\" Y value\n",
    "    return rmsle(np.expm1(val_y), predicted_vals), myModel #include transform of val_Y values from log to \"normal\" Y value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "6b2814af-4f93-4e0c-8495-b0db3dcbfa79",
    "_uuid": "469feb2739ff62277c5bb52eb6b6776e58a89aed"
   },
   "outputs": [],
   "source": [
    "def ScoreCombos (SeedVal, df_X, logy, ScoreAllCombos, ls_PredictorCombos, i_n_estimators=10,i_min_samples_leaf=1, i_max_leaf_nodes=None, pct_max_features = 100, i_n_jobs=1):\n",
    "    #find RMSLE error of each predictor combination\n",
    "    #return dataframe of results: ComboID\terr\tPreds\n",
    "    MinErr = 100000000\n",
    "#     df_Track = pd.DataFrame()\n",
    "    bestModel = None\n",
    "    if ScoreAllCombos:\n",
    "        for comboID in range(1,len(ls_PredictorCombos)):\n",
    "            X = GetX(comboID, df_X)\n",
    "            TrainErr,myModel = Run_RFG(SeedVal, X, logy, i_n_estimators,i_min_samples_leaf, i_max_leaf_nodes, pct_max_features, i_n_jobs)\n",
    "    #         df2 = pd.DataFrame([[comboID, TrainErr, ','.join(ls_PredictorCombos[comboID])]],columns=['ComboID','err','Preds'])\n",
    "    #         if df_Track.shape[0] >0:\n",
    "    #             df_Track = pd.concat([df2, df_Track])\n",
    "    #         else:\n",
    "    #             df_Track = df2.copy(deep = True)\n",
    "            if TrainErr < MinErr:\n",
    "                MinErr = TrainErr\n",
    "                bestComboID = comboID\n",
    "                bestModel = myModel\n",
    "                print ('Best Combo: ', bestComboID, ' Params: ', ls_PredictorCombos[comboID], ' Err: ', TrainErr)\n",
    "    else:\n",
    "            X = df_X[ls_PredictorCombos]\n",
    "            TrainErr,myModel = Run_RFG(SeedVal, X, logy, i_n_estimators,i_min_samples_leaf, i_max_leaf_nodes, pct_max_features, i_n_jobs)\n",
    "    #         df2 = pd.DataFrame([[comboID, TrainErr, ','.join(ls_PredictorCombos[comboID])]],columns=['ComboID','err','Preds'])\n",
    "    #         if df_Track.shape[0] >0:\n",
    "    #             df_Track = pd.concat([df2, df_Track])\n",
    "    #         else:\n",
    "    #             df_Track = df2.copy(deep = True)\n",
    "            if TrainErr < MinErr:\n",
    "                MinErr = TrainErr\n",
    "                bestComboID = 0\n",
    "                bestModel = myModel\n",
    "                print ('Best Combo: ', bestComboID, ' Params: ', ls_PredictorCombos, ' Err: ', TrainErr)\n",
    "        \n",
    "    print ('fin')\n",
    "#     return df_Track\n",
    "    return MinErr, bestComboID, bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[   7. 1827. 1248. ...   74. 2376. 2143.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-c5bc3ff3e40a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mls_PredictorCombos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'invoice_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'customer_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'unit_price'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mSeedVal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcurErr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurComboID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mScoreCombos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSeedVal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mls_PredictorCombos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-e07330c2c2c8>\u001b[0m in \u001b[0;36mScoreCombos\u001b[1;34m(SeedVal, df_X, logy, ScoreAllCombos, ls_PredictorCombos, i_n_estimators, i_min_samples_leaf, i_max_leaf_nodes, pct_max_features, i_n_jobs)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcomboID\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mls_PredictorCombos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGetX\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomboID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mTrainErr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmyModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRun_RFG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSeedVal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_n_estimators\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi_min_samples_leaf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_max_leaf_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpct_max_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m#         df2 = pd.DataFrame([[comboID, TrainErr, ','.join(ls_PredictorCombos[comboID])]],columns=['ComboID','err','Preds'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#         if df_Track.shape[0] >0:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-14ec406295db>\u001b[0m in \u001b[0;36mRun_RFG\u001b[1;34m(SeedVal, X, logy, i_n_estimators, i_min_samples_leaf, i_max_leaf_nodes, pct_max_features, i_n_jobs)\u001b[0m\n\u001b[0;32m     13\u001b[0m         random_state=SeedVal)\n\u001b[0;32m     14\u001b[0m     \u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeedVal\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#split training data into a test and train part\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mmyModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mpredicted_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#transform predicted values from log to \"normal\" Y value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrmsle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmyModel\u001b[0m \u001b[1;31m#include transform of val_Y values from log to \"normal\" Y value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    245\u001b[0m         \"\"\"\n\u001b[0;32m    246\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    439\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[1;31m# To ensure that array flags are maintained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[   7. 1827. 1248. ...   74. 2376. 2143.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "ls_PredictorCombos = ['invoice_id', 'customer_id', 'unit_price']\n",
    "SeedVal = 0\n",
    "curErr, curComboID, curModel = ScoreCombos(SeedVal, df_train, logy, True, ls_PredictorCombos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def leftORRight():\n",
    "    ls_leftORright = [-1,1]\n",
    "    return ls_leftORright[random.randint(0,1)]\n",
    "#     return -1 #for now, force left\n",
    "\n",
    "def HopToVal(HopFactor, CurVal, r_vals):\n",
    "    #hop to another value within range R_vals that is at most HopFactor% away from current value\n",
    "    #returned value is float so you'll need to round and cast (Say to int) if needed\n",
    "    xrMin = r_vals[0]\n",
    "    xrMax = r_vals[len(r_vals)-1]\n",
    "    LR = leftORRight()\n",
    "    if LR < 0:\n",
    "        HopDistMax = xrMin-CurVal\n",
    "    else:\n",
    "        HopDistMax = xrMax-CurVal\n",
    "    x1 = CurVal + HopDistMax * random.uniform(0,HopFactor)\n",
    "    if x1 < xrMin: x1=xrMin\n",
    "    return x1\n",
    "\n",
    "def TuneParams_RW(df_X, logy, ScoreAllCombos, ls_PredictorCombos, MaxWalks,  r_n_estimators, r_min_samples_leaf, r_max_leaf_nodes, r_pct_max_features, i_n_jobs, SeedVal):\n",
    "    # find best model param combo using random walk\n",
    "    random.seed(SeedVal)\n",
    "    bestModel = None\n",
    "    bestComboID = 0\n",
    "    bestErr = 100000000\n",
    "    #set some intial values for each tuning parameter (they won't be used - just need to give values to do initial hop on)\n",
    "    n_estimators = r_n_estimators[0]\n",
    "    min_samples_leaf = r_min_samples_leaf[0]\n",
    "    max_leaf_nodes = r_max_leaf_nodes[0]\n",
    "    pct_max_features = r_pct_max_features[0]\n",
    "    for Walki in range(0,MaxWalks):\n",
    "        #assign values:\n",
    "        print ('Evaluating tuning params: n_estimators: ', n_estimators, 'min_samples_leaf: ', min_samples_leaf, 'max_leaf_nodes: ', max_leaf_nodes,)\n",
    "        n_estimators = int(round(HopToVal(1,n_estimators,r_n_estimators),0))\n",
    "        min_samples_leaf = int(round(HopToVal(1,min_samples_leaf, r_min_samples_leaf),0))\n",
    "        max_leaf_nodes = int(round(HopToVal(1,max_leaf_nodes, r_max_leaf_nodes),0))\n",
    "        pct_max_features = int(round(HopToVal(1,pct_max_features, r_pct_max_features),0))\n",
    "        curErr, curComboID, curModel = ScoreCombos(SeedVal, df_X, logy, ScoreAllCombos, ls_PredictorCombos, n_estimators, min_samples_leaf, max_leaf_nodes, pct_max_features, i_n_jobs)\n",
    "        if curErr < bestErr:\n",
    "            bestErr = curErr\n",
    "            bestComboID = curComboID\n",
    "            bestModel = curModel\n",
    "            print ('!!!New best tuning: \\npredictors: ', curModel.get_params(deep=True),  ' model error: ', bestErr, ' n_estimators: ', n_estimators, 'min_samples_leaf: ', min_samples_leaf, 'max_leaf_nodes: ', max_leaf_nodes,)\n",
    "        # clear_output()\n",
    "    return bestErr, bestComboID, bestModel\n",
    "#     print ('--- Completed sim runs for tgtRR: ',tgtRR)\n",
    "#     print ('--- %s execution time in seconds ---' % (time.time() - start_time))\n",
    "#     return [ls_best, pd_hist]\n",
    "\n",
    "# TuneParams_RW(df_train, logy, False, ['invoice_id', 'customer_id', 'unit_price'], 1, range(10,100), range(1,2), range(5,50), 4, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TMax=1.0\n",
    "# TMin = 0.01\n",
    "# Talpha = 0.75\n",
    "# MaxWalks = 500\n",
    "# Tstepcnt = 0 #initialize counter of number of steps between 1st T and T_Min\n",
    "# #calculate number of walks per Tstep\n",
    "# T = TMax #setup T for calculation\n",
    "# while T >= TMin:\n",
    "#     T = T * Talpha\n",
    "#     Tstepcnt += 1\n",
    "\n",
    "# WalksPerTstep = int (MaxWalks / Tstepcnt) #walks per Tstep\n",
    "# print ('Walks per T step: ', WalksPerTstep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating tuning params: n_estimators:  100 min_samples_leaf:  1 max_leaf_nodes:  5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-039c62394e84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbestErr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbestComboID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbestModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m \u001b[0mTuneParams_SA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'invoice_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'customer_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'unit_price'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.80\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.75\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-039c62394e84>\u001b[0m in \u001b[0;36mTuneParams_SA\u001b[1;34m(df_X, logy, ScoreAllCombos, ls_PredictorCombos, MaxWalks, NoPrgNextT, TMin, Talpha, r_n_estimators, r_min_samples_leaf, r_max_leaf_nodes, r_pct_max_features, i_n_jobs, SeedVal)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m#we need 2 error measurements (prevErr and curErr) before entering SA. do this by doing 2 random walk results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     prevErr, prevComboID, prevModel = TuneParams_RW(df_X, logy, ScoreAllCombos, ls_PredictorCombos, 1, \n\u001b[1;32m---> 18\u001b[1;33m                 r_n_estimators, r_min_samples_leaf, r_max_leaf_nodes, r_pct_max_features, i_n_jobs, SeedVal)\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprevErr\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mbestErr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mbestErr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevErr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-6e7ce2e57242>\u001b[0m in \u001b[0;36mTuneParams_RW\u001b[1;34m(df_X, logy, ScoreAllCombos, ls_PredictorCombos, MaxWalks, r_n_estimators, r_min_samples_leaf, r_max_leaf_nodes, r_pct_max_features, i_n_jobs, SeedVal)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mmax_leaf_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHopToVal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_max_leaf_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mpct_max_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHopToVal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpct_max_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_pct_max_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mcurErr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurComboID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mScoreCombos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSeedVal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mScoreAllCombos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mls_PredictorCombos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpct_max_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcurErr\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mbestErr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mbestErr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurErr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-e07330c2c2c8>\u001b[0m in \u001b[0;36mScoreCombos\u001b[1;34m(SeedVal, df_X, logy, ScoreAllCombos, ls_PredictorCombos, i_n_estimators, i_min_samples_leaf, i_max_leaf_nodes, pct_max_features, i_n_jobs)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcomboID\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mls_PredictorCombos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGetX\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomboID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mTrainErr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmyModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRun_RFG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSeedVal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_n_estimators\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi_min_samples_leaf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_max_leaf_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpct_max_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m#         df2 = pd.DataFrame([[comboID, TrainErr, ','.join(ls_PredictorCombos[comboID])]],columns=['ComboID','err','Preds'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#         if df_Track.shape[0] >0:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-14ec406295db>\u001b[0m in \u001b[0;36mRun_RFG\u001b[1;34m(SeedVal, X, logy, i_n_estimators, i_min_samples_leaf, i_max_leaf_nodes, pct_max_features, i_n_jobs)\u001b[0m\n\u001b[0;32m     13\u001b[0m         random_state=SeedVal)\n\u001b[0;32m     14\u001b[0m     \u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeedVal\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#split training data into a test and train part\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mmyModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mpredicted_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#transform predicted values from log to \"normal\" Y value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrmsle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmyModel\u001b[0m \u001b[1;31m#include transform of val_Y values from log to \"normal\" Y value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 328\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    697\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def prAccept(prevErr, curErr, T):\n",
    "    try:\n",
    "        prob = math.exp((prevErr - curErr)/T)\n",
    "    except OverflowError:\n",
    "        prob = 1 #calculated number is infinite. make prob = 1\n",
    "    return prob\n",
    "\n",
    "def TuneParams_SA(df_X, logy, ScoreAllCombos, ls_PredictorCombos, MaxWalks, NoPrgNextT, TMin, Talpha,\n",
    "                  r_n_estimators, r_min_samples_leaf, r_max_leaf_nodes, r_pct_max_features, i_n_jobs, SeedVal):\n",
    "    # find best model param combo using simulated annealing\n",
    "    random.seed(SeedVal)\n",
    "    bestModel = None\n",
    "    bestComboID = 0\n",
    "    bestErr = 100000000\n",
    "    \n",
    "    #we need 2 error measurements (prevErr and curErr) before entering SA. do this by doing 2 random walk results\n",
    "    prevErr, prevComboID, prevModel = TuneParams_RW(df_X, logy, ScoreAllCombos, ls_PredictorCombos, 1, \n",
    "                r_n_estimators, r_min_samples_leaf, r_max_leaf_nodes, r_pct_max_features, i_n_jobs, SeedVal)\n",
    "    if prevErr < bestErr:\n",
    "        bestErr = prevErr\n",
    "        bestComboID = prevComboID\n",
    "        bestModel = prevModel\n",
    "        print ('!!!New best tuning: \\npredictors: ', bestModel.get_params(deep=True),  ' model error: ', bestErr, ' n_estimators: ', bestModel.n_estimators, 'min_samples_leaf: ', bestModel.min_samples_leaf, 'max_leaf_nodes: ', bestModel.max_leaf_nodes,)\n",
    "    curErr, curComboID, curModel = TuneParams_RW(df_X, logy, ScoreAllCombos, ls_PredictorCombos, 1, \n",
    "                 r_n_estimators, r_min_samples_leaf, r_max_leaf_nodes, r_pct_max_features, i_n_jobs, SeedVal)\n",
    "    if curErr < bestErr:\n",
    "        bestErr = curErr\n",
    "        bestComboID = curComboID\n",
    "        bestModel = curModel\n",
    "        print ('!!!New best tuning: \\npredictors: ', bestModel.get_params(deep=True),  ' model error: ', bestErr, ' n_estimators: ', bestModel.n_estimators, 'min_samples_leaf: ', bestModel.min_samples_leaf, 'max_leaf_nodes: ', bestModel.max_leaf_nodes,)    \n",
    "    WalkNo = 2\n",
    "    \n",
    "    #get ready to enter SA loop:\n",
    "    TMax=1.0\n",
    "    Tstepcnt = 0 #initialize counter of number of steps between 1st T and T_Min\n",
    "    #calculate number of walks per Tstep\n",
    "    T = TMax #setup T for calculation\n",
    "    while T >= TMin:\n",
    "        T = T * Talpha\n",
    "        Tstepcnt += 1\n",
    "    WalksPerTstep = int (MaxWalks / Tstepcnt) #walks per Tstep\n",
    "    print ('Walks per T step: ', WalksPerTstep)\n",
    "    T = TMax #Reset T\n",
    "    NoPrgWalkCnt = 0\n",
    "    #enter SA loop:\n",
    "    while T > TMin:\n",
    "        for iterAtT in range (0,WalksPerTstep): #for each temp, do sim. runs\n",
    "            #advance iterators:\n",
    "            WalkNo = WalkNo + 1\n",
    "            if WalkNo > MaxWalks:\n",
    "                break\n",
    "            if iterAtT>0:\n",
    "                prAcceptVal = prAccept(prevErr, curErr, T) #PROBABILITY OF ACCEPTING SOLUTION. PR > 1 FOR IMPROVED SOLUTION. PR [0,1] FOR WORSTEND SOLUTION\n",
    "                prRandVal = random.uniform(0,1.0)\n",
    "                # print ('Acceptance Consideration: T: ', T, ' prAccept: ', prAcceptVal, ' prRandVal: ', prRandVal)\n",
    "                if prAcceptVal > prRandVal: #accept current solution & base next solution on current solution\n",
    "                    n_estimators = int(round(HopToVal(T,curModel.n_estimators,r_n_estimators),0))\n",
    "                    min_samples_leaf = int(round(HopToVal(T,curModel.min_samples_leaf, r_min_samples_leaf),0))\n",
    "                    max_leaf_nodes = int(round(HopToVal(T,curModel.max_leaf_nodes, r_max_leaf_nodes),0))\n",
    "                    pct_max_features = int(round(HopToVal(T,curModel.max_features*100, r_pct_max_features),0))\n",
    "                    prevModel = curModel\n",
    "                    prevComboID = curComboID\n",
    "                    prevErr = curErr\n",
    "                else: #reject current solution & base next solution on prior solution\n",
    "                    n_estimators = int(round(HopToVal(T,prevModel.n_estimators,r_n_estimators),0))\n",
    "                    min_samples_leaf = int(round(HopToVal(T,prevModel.min_samples_leaf, r_min_samples_leaf),0))\n",
    "                    max_leaf_nodes = int(round(HopToVal(T,prevModel.max_leaf_nodes, r_max_leaf_nodes),0))\n",
    "                    pct_max_features = int(round(HopToVal(T,prevModel.max_features*100, r_pct_max_features),0))                    \n",
    "            else: #reset to best position at each new temp\n",
    "                    print ('Resetting to best params')\n",
    "                    n_estimators = int(round(HopToVal(T,bestModel.n_estimators,r_n_estimators),0))\n",
    "                    min_samples_leaf = int(round(HopToVal(T,bestModel.min_samples_leaf, r_min_samples_leaf),0))\n",
    "                    max_leaf_nodes = int(round(HopToVal(T,bestModel.max_leaf_nodes, r_max_leaf_nodes),0))\n",
    "                    pct_max_features = int(round(HopToVal(T,bestModel.max_features*100, r_pct_max_features),0))\n",
    "                    prevModel = bestModel\n",
    "                    prevComboID = bestComboID\n",
    "                    prevErr = bestErr                    \n",
    "            #assign values:\n",
    "            print ('\\nWalkNo: ', WalkNo)\n",
    "            print ('Evaluating tuning params: n_estimators: ', n_estimators, 'min_samples_leaf: ', min_samples_leaf, 'max_leaf_nodes: ', max_leaf_nodes, ' pct_max_features: ', pct_max_features)\n",
    "            curErr, curComboID, curModel = ScoreCombos(SeedVal, df_X, logy, ScoreAllCombos, ls_PredictorCombos, n_estimators, min_samples_leaf, max_leaf_nodes, pct_max_features, i_n_jobs)\n",
    "            if curErr < bestErr:\n",
    "                bestErr = curErr\n",
    "                bestComboID = curComboID\n",
    "                bestModel = curModel\n",
    "                print ('!!!New best tuning: \\npredictors: ', bestModel.get_params(deep=True),  ' model error: ', bestErr, ' n_estimators: ', bestModel.n_estimators, 'min_samples_leaf: ', bestModel.min_samples_leaf, 'max_leaf_nodes: ', bestModel.max_leaf_nodes,)    \n",
    "                NoPrgWalkCnt =0 \n",
    "            else:\n",
    "                NoPrgWalkCnt += 1\n",
    "                if NoPrgNextT < NoPrgWalkCnt / MaxWalks: #leave current temperature step if no progress made\n",
    "                    break\n",
    "        #advance iterators:\n",
    "        T = T * Talpha\n",
    "        NoPrgWalkCnt = 0\n",
    "        if WalkNo > MaxWalks:\n",
    "            break\n",
    "            \n",
    "    return bestErr, bestComboID, bestModel\n",
    "\n",
    "TuneParams_SA(df_train, logy, True, ['invoice_id', 'customer_id', 'unit_price'], 50, 0.80, 0.01, 0.75, range(100,5000), range(1,2), range(5,5000), range(1,100), -1, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "99b26b10-ddd8-405f-a589-334476fd06ad",
    "_uuid": "794e134f3ba5b7dd629c8c6d011aa58c27d610c7"
   },
   "source": [
    "## OBSERVATION:  customer id & unit price are a part of the lowest 4 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "d1e23de2-53f1-49bd-bcdf-4b0e211095c3",
    "_uuid": "10778e39054b5a38bdfe544a2297395b39de4037"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_Track' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-211058f7a29c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_Track\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'err'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_Track' is not defined"
     ]
    }
   ],
   "source": [
    "df_Track.sort_values(by=['err'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1858a70f-6e7b-4b31-a151-3de60d958dfb",
    "_uuid": "568860a9ef9d1a328d721e4b420e3f3e2e44cd1c"
   },
   "source": [
    "# Submit Model's Predictions\n",
    "## First, output model's predictions for test data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "8942ec81-8192-4f6c-87fc-f73be942a51c",
    "_uuid": "116ea6bb0872567d756397cee42aa4661a337c5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4.1609216   15.53076939  13.03261551 ...,   2.44194547   1.01317254\n",
      "   2.05402861]\n"
     ]
    }
   ],
   "source": [
    "test_X = df_test[ls_mypredictors]\n",
    "# Use the model to make predictions\n",
    "predicted_vals = myModel.predict(test_X)\n",
    "predicted_vals = np.expm1(myModel.predict(test_X)) #transform from log to \"normal\" Y value\n",
    "# We will look at the predicted prices to ensure we have something sensible.\n",
    "print(predicted_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "98a8ec9d-dca0-49d9-be93-100cb148aae5",
    "_uuid": "a516788fc3ada35a38f934e6135fb154e85c144a"
   },
   "source": [
    "## Next, submit predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "14896579-61d8-4516-a437-2e8d10554b44",
    "_uuid": "b71f002254f76498e9a46941ec7700c938470cbe",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'Id': df_test.id, 'quantity': predicted_vals})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "994af692-ad37-4f64-95be-4e66077f3864",
    "_uuid": "b06695c97943358fcc9924ac8dab4dc17f43922a",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

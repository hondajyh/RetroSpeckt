{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7fbfb891-6794-4584-9c00-ede5e8a8ba0f",
    "_uuid": "5aca4e1b81b52102ec85a107f821714014f0bdf1"
   },
   "source": [
    "# JON'S HiML Competition XGB_Log Model (v 3.0)\n",
    "## Make Date: 04/13/18\n",
    "Can XGBoost improve our prediction accuracy?  Use model 2.2, except use XGB instead of random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "#Some initialization procedures:\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "# load in data files\n",
    "# FILE_DIR = '../input/hawaiiml-data'\n",
    "# for f in os.listdir(FILE_DIR):\n",
    "#     print('{0:<30}{1:0.2f}MB'.format(f, 1e-6*os.path.getsize(f'{FILE_DIR}/{f}')))\n",
    "\n",
    "\n",
    "FILE_DIR = '../Sprint09alt_Machine_Learning_Hawaii_Kaggle_Competition'\n",
    "df_train = pd.read_csv(f'{FILE_DIR}/train.csv', encoding='ISO-8859-1') #write training data to dataframe\n",
    "df_test = pd.read_csv(f'{FILE_DIR}/test.csv', encoding='ISO-8859-1') # Read the test data\n",
    "\n",
    "#define the error function:\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((np.log1p(y_true) - np.log1p(y_pred))**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ff9f1761-c91d-4ee4-bfe8-a9b09b7ee31a",
    "_uuid": "4b5c96480b52b12cb00f951f4caf86bee8671a1a"
   },
   "source": [
    "# Prediction Target\n",
    "We want to predict the quantity data field.    \n",
    "By convention, we define this target as 'y'.  \n",
    "We know quantity is highly skewed. See if a log transform will help.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "e9777448-7e1c-4431-91ba-8278ef408e90",
    "_uuid": "7ce0ac11027bab5c459434ee85fdf943bf655e3e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df_train.quantity\n",
    "logy = np.log1p(df_train.quantity)\n",
    "df_train['log1p_quantity'] = np.log1p(df_train.quantity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6e238f2d-a45d-4a56-8361-2b3ec095f0d9",
    "_uuid": "73ba8ee97398266d6c990f5142b368d2d2c62e6f"
   },
   "source": [
    "# Train Model\n",
    "setup XGB using these site:   \n",
    "  https://machinelearningmastery.com/develop-first-xgboost-model-python-scikit-learn/  \n",
    "  https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/  \n",
    "For now, just try out numerics - drop all nonnumerics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "f4cdd3d8-0cf2-4fc9-8460-7e404df28a59",
    "_uuid": "0c49ba89accc41b6e014182736ff24fcdfe4d7c0",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train.drop(['date','time','country','description'], axis=1, inplace=True)\n",
    "df_test.drop(['date','time','country','description'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "f5b90f23-c3f9-4081-86c1-2a08a51f8d29",
    "_uuid": "85b8f21545682e749c0227f06183b0d53ccd35b0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TrainModel(ls_AllPredictors, df_X, logy, myModel):\n",
    "    #use passed in myModel: train, make prediction, and then evaluate predition.\n",
    "    train_X, val_X, train_y, val_y = train_test_split(df_X[ls_AllPredictors], logy, random_state = 0) #split training data into a test and train part\n",
    "    myModel.fit(train_X, train_y)  \n",
    "    # make predictions for test data\n",
    "    pred_y = myModel.predict(val_X)\n",
    "    # predictions = [round(value) for value in pred_y]\n",
    "    err = rmsle(np.expm1(val_y), np.expm1(pred_y)) #include transform of val_Y values from log to \"normal\" Y value  \n",
    "    return err, myModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "0cc0ffc4-f8d8-4b97-835f-520edcb26b1a",
    "_uuid": "6efd8894cdd58f854dd2cfbb57d37e7e0b0d6ef2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leftORRight():\n",
    "    ls_leftORright = [-1,1]\n",
    "    return ls_leftORright[random.randint(0,1)]\n",
    "#     return -1 #for now, force left\n",
    "\n",
    "def HopToVal(HopFactor, CurVal, r_vals):\n",
    "    #hop to another value within range R_vals that is at most HopFactor% away from current value\n",
    "    #returned value is float so you'll need to round and cast (Say to int) if needed\n",
    "    xrMin = r_vals[0]\n",
    "    xrMax = r_vals[len(r_vals)-1]\n",
    "    LR = leftORRight()\n",
    "    if LR < 0:\n",
    "        HopDistMax = xrMin-CurVal\n",
    "    else:\n",
    "        HopDistMax = xrMax-CurVal\n",
    "    x1 = CurVal + HopDistMax * HopFactor * random.uniform(0,HopFactor)\n",
    "    if x1 < xrMin: x1=xrMin\n",
    "    return x1\n",
    "    \n",
    "def prAccept(prevErr, curErr, T):\n",
    "    try:\n",
    "        prob = math.exp((prevErr - curErr)/T)\n",
    "    except OverflowError:\n",
    "        prob = 1 #calculated number is infinite. make prob = 1\n",
    "    return prob\n",
    "\n",
    "def AssignModelParams(i_n_estimators, i_max_depth, SeedVal):\n",
    "    #set model values using passed in parameters. use predetermined values for everythin else\n",
    "    myModel = xgb.XGBRegressor(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=i_n_estimators,\n",
    "        max_depth=i_max_depth,\n",
    "        early_stopping_rounds=5,\n",
    "        nthread=8,\n",
    "        seed=SeedVal)  \n",
    "    return myModel\n",
    "       \n",
    "def FindBestModel(ls_AllPredictors, df_X, logy, \n",
    "                 MaxWalks, \n",
    "                 r_n_estimators, r_max_depth,\n",
    "                 SeedVal\n",
    "                 ):\n",
    "    #tune till we find the best set of model parameters\n",
    "    #FOR NOW DO A SIMPLISTIC RANDOM OPTIMIZATION SEARCH THAT DOES RANDOM HOPS. IF HOP LOCATION IMPROVES ERROR, THEN USE THAT HOP AS JUMP POINT FOR NEXT HOP\n",
    "    #AS WE PROCEED TO TOWARD MAXWALK, HOP DIST APPROACHES 0\n",
    "    bestErr = 100000000\n",
    "    i_n_estimators = r_n_estimators[0]\n",
    "    i_max_depth = r_max_depth[0] \n",
    "    T = 1\n",
    "    for WalkNo in range (0, MaxWalks):\n",
    "        myModel = AssignModelParams(i_n_estimators, i_max_depth, SeedVal)\n",
    "        curErr, myModel = TrainModel(ls_AllPredictors, df_X, logy, myModel)\n",
    "        print ('Cur trial:', WalkNo, '  Trained with params: myModel.n_estimators', myModel.n_estimators, 'myModel.max_depth', myModel.max_depth, ' ERR:',curErr)\n",
    "        if curErr < bestErr:\n",
    "            bestModel = myModel\n",
    "            bestErr = curErr\n",
    "            print ('!!!!NEW BEST: err:', bestErr)\n",
    "            #use last estimator as hop off point for next parameter\n",
    "            i_n_estimators = int(round(HopToVal(T,i_n_estimators,r_n_estimators),0))\n",
    "            i_max_depth = int(round(HopToVal(T,i_max_depth, r_max_depth),0))\n",
    "        else:\n",
    "            #use best estimator as hop off point for next parameter\n",
    "            i_n_estimators = int(round(HopToVal(T,bestModel.n_estimators,r_n_estimators),0))\n",
    "            i_max_depth = int(round(HopToVal(T,bestModel.max_depth, r_max_depth),0))            \n",
    "        T = 1 - WalkNo/MaxWalks\n",
    "    return bestErr, bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "bd531c8d-5c7b-4506-9a68-7563b88ee6a9",
    "_uuid": "69860fe045844b906db7f6d0ce5e81d8931415f7",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'early_stopping_rounds'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-85fd8b2d6c35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mls_AllPredictors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'invoice_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'stock_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'customer_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'unit_price'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbestErr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbestModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFindBestModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mls_AllPredictors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-30f5ef5a81b8>\u001b[0m in \u001b[0;36mFindBestModel\u001b[1;34m(ls_AllPredictors, df_X, logy, MaxWalks, r_n_estimators, r_max_depth, SeedVal)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mWalkNo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxWalks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mmyModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAssignModelParams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi_n_estimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_max_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeedVal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mcurErr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmyModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrainModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mls_AllPredictors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmyModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Cur trial:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWalkNo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'  Trained with params: myModel.n_estimators'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmyModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'myModel.max_depth'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmyModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' ERR:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcurErr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-30f5ef5a81b8>\u001b[0m in \u001b[0;36mAssignModelParams\u001b[1;34m(i_n_estimators, i_max_depth, SeedVal)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mnthread\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         seed=SeedVal)  \n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmyModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'early_stopping_rounds'"
     ]
    }
   ],
   "source": [
    "ls_AllPredictors = ['id','invoice_id', 'stock_id', 'customer_id', 'unit_price']\n",
    "bestErr, bestModel = FindBestModel(ls_AllPredictors, df_train, logy, 14, range(1,5000), range(6,30),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1858a70f-6e7b-4b31-a151-3de60d958dfb",
    "_uuid": "568860a9ef9d1a328d721e4b420e3f3e2e44cd1c"
   },
   "source": [
    "# Submit Model's Predictions\n",
    "## First, output model's predictions for test data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "8942ec81-8192-4f6c-87fc-f73be942a51c",
    "_uuid": "116ea6bb0872567d756397cee42aa4661a337c5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.260911  7.2110157 9.191854  ... 2.867107  1.5157086 2.127908 ]\n"
     ]
    }
   ],
   "source": [
    "# Use the model to make predictions\n",
    "predicted_vals = bestModel.predict(df_test)\n",
    "predicted_vals = np.expm1(bestModel.predict(df_test)) #transform from log to \"normal\" Y value\n",
    "# We will look at the predicted prices to ensure we have something sensible.\n",
    "print(predicted_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "98a8ec9d-dca0-49d9-be93-100cb148aae5",
    "_uuid": "a516788fc3ada35a38f934e6135fb154e85c144a"
   },
   "source": [
    "## Next, submit predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "14896579-61d8-4516-a437-2e8d10554b44",
    "_uuid": "b71f002254f76498e9a46941ec7700c938470cbe",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'Id': df_test.id, 'quantity': predicted_vals})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "994af692-ad37-4f64-95be-4e66077f3864",
    "_uuid": "b06695c97943358fcc9924ac8dab4dc17f43922a",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
